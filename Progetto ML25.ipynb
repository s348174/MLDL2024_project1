{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "36xvd24zrqqh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda\n",
        "from torchvision import transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "import time\n",
        "import os\n",
        "from PIL import Image\n",
        "from tempfile import TemporaryDirectory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# NEED TO RUN AT AVERY NEW RUNTIME\n",
        "# Setup google drive connection\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from google.colab import auth\n",
        "\n",
        "# Autenticazione\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ],
      "metadata": {
        "id": "eRCAYuL9uH_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7d03e1-0c8d-4273-d5f5-c6ed23ca2b0a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TO BE RUNNED JUST THE FIRST TIME!\n",
        "# Setup git integration\n",
        "%cd /content/drive/MyDrive\n",
        "!git clone https://github.com/s348174/MLDL2024_project1.git\n",
        "%cd"
      ],
      "metadata": {
        "id": "jq91B_2IAZcN",
        "outputId": "d6a6acfe-e204-497b-f980-72803305e576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n",
            "Cloning into 'MLDL2024_project1'...\n",
            "remote: Enumerating objects: 80, done.\u001b[K\n",
            "remote: Counting objects: 100% (69/69), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 80 (delta 25), reused 45 (delta 13), pack-reused 11 (from 2)\u001b[K\n",
            "Receiving objects: 100% (80/80), 752.09 KiB | 8.09 MiB/s, done.\n",
            "Resolving deltas: 100% (25/25), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RUN EVERYTIME IN ORDER TO AVOID CONFLICTS\n",
        "# Update drive git directory\n",
        "%cd /content/drive/MyDrive/MLDL2024_project1\n",
        "!git pull\n",
        "%cd"
      ],
      "metadata": {
        "id": "XvTUimb9uK5Z",
        "outputId": "09c6dd18-6c04-409a-91e5-0a61c525490e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLDL2024_project1\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0 (from 0)\u001b[K\n",
            "Unpacking objects: 100% (3/3), 296 bytes | 0 bytes/s, done.\n",
            "From https://github.com/s348174/MLDL2024_project1\n",
            "   4d7670a..d8f3838  master     -> origin/master\n",
            "Updating 4d7670a..d8f3838\n",
            "Fast-forward\n",
            " train.py | 6 \u001b[32m+++\u001b[m\u001b[31m---\u001b[m\n",
            " 1 file changed, 3 insertions(+), 3 deletions(-)\n",
            "/root\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "from tempfile import TemporaryDirectory\n",
        "\n",
        "# Add the directory containing train.py to the system path\n",
        "google_drive_path = '/content/drive/MyDrive/MLDL2024_project1'\n",
        "sys.path.append(google_drive_path)\n",
        "#datasets_folder_path = '/content/drive/MyDrive/MLDL2024_project1/datasets'\n",
        "#sys.path.append(datasets_folder_path)\n",
        "#models_path = '/content/drive/MyDrive/MLDL2024_project1/models/deeplabv2'\n",
        "#sys.path.append(models_path)\n",
        "from train import deeplab_train\n",
        "\n",
        "# Open zipfile\n",
        "import zipfile\n",
        "zip_path = '/content/drive/MyDrive/machine_learning_shared_2025/Cityscapes.zip'\n",
        "with zipfile.ZipFile(zip_path) as z:\n",
        "  # Mostra i file contenuti\n",
        "  #print(\"Contenuto dello ZIP:\", z.namelist())\n",
        "  with TemporaryDirectory() as tmpdir:\n",
        "    z.extractall(tmpdir)\n",
        "    #image_folder_path=tmpdir+\"/Cityscapes/Cityspaces/images/train\"\n",
        "    #train_data = datasets.ImageFolder(\n",
        "    #    root=image_folder_path,\n",
        "    #    transform=ToTensor()\n",
        "    #)\n",
        "    #test_folder_path=tmpdir+\"/Cityscapes/Cityspaces/images/test\"\n",
        "    #test_data = datasets.ImageFolder(\n",
        "    #    root=image_folder_path,\n",
        "    #    transform=ToTensor()\n",
        "    #)\n",
        "\n",
        "    # Creates symlink to data folder\n",
        "    real_path = \"tmpdir\"\n",
        "    destinazione_symlink = \"/tmp/tmpcp08lfus\"\n",
        "    if not os.path.exists(destinazione_symlink):\n",
        "        os.symlink(real_path, destinazione_symlink)\n",
        "\n",
        "    dataset_path = tmpdir+\"/Cityscapes/Cityspaces\"\n",
        "    deeplab_train(dataset_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "ce9lSdNSyOin",
        "outputId": "fea039c3-4a70-42d3-ad07-3fbaa5757000"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'train'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-cead1712d732>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/drive/MyDrive/MLDL2024_project1/models/deeplabv2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeeplab_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Open zipfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'train'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9pt4D4j89jTY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}