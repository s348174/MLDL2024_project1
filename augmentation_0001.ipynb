{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcfe337-b976-43f4-8827-f8c8ac3d3735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 500 images and 500 labels\n",
      "Image map: 500\n",
      "Matched 500 image-label pairs\n",
      "Running BiSeNet inference...\n",
      "Iteration 0/500, Latency: 0.5412s, FPS: 1.85\n",
      "Iteration 10/500, Latency: 0.4087s, FPS: 2.45\n",
      "Iteration 20/500, Latency: 0.4053s, FPS: 2.47\n",
      "Iteration 30/500, Latency: 0.3541s, FPS: 2.82\n",
      "Iteration 40/500, Latency: 0.4118s, FPS: 2.43\n",
      "Iteration 50/500, Latency: 0.3490s, FPS: 2.86\n",
      "Iteration 60/500, Latency: 0.3869s, FPS: 2.58\n",
      "Iteration 70/500, Latency: 0.3885s, FPS: 2.57\n",
      "Iteration 80/500, Latency: 0.3868s, FPS: 2.58\n",
      "Iteration 90/500, Latency: 0.3915s, FPS: 2.55\n",
      "Iteration 100/500, Latency: 0.3935s, FPS: 2.54\n",
      "Iteration 110/500, Latency: 0.3924s, FPS: 2.55\n",
      "Iteration 120/500, Latency: 0.4021s, FPS: 2.49\n",
      "Iteration 130/500, Latency: 0.3957s, FPS: 2.53\n",
      "Iteration 140/500, Latency: 0.3916s, FPS: 2.55\n",
      "Iteration 150/500, Latency: 0.3848s, FPS: 2.60\n",
      "Iteration 160/500, Latency: 0.3932s, FPS: 2.54\n",
      "Iteration 170/500, Latency: 0.4459s, FPS: 2.24\n",
      "Iteration 180/500, Latency: 0.3894s, FPS: 2.57\n",
      "Iteration 190/500, Latency: 0.3927s, FPS: 2.55\n",
      "Iteration 200/500, Latency: 0.3902s, FPS: 2.56\n",
      "Iteration 210/500, Latency: 0.3922s, FPS: 2.55\n",
      "Iteration 220/500, Latency: 0.3781s, FPS: 2.64\n",
      "Iteration 230/500, Latency: 0.3765s, FPS: 2.66\n",
      "Iteration 240/500, Latency: 0.3792s, FPS: 2.64\n",
      "Iteration 250/500, Latency: 0.3818s, FPS: 2.62\n",
      "Iteration 260/500, Latency: 0.3899s, FPS: 2.57\n",
      "Iteration 270/500, Latency: 0.3825s, FPS: 2.61\n",
      "Iteration 280/500, Latency: 0.3809s, FPS: 2.63\n",
      "Iteration 290/500, Latency: 0.3795s, FPS: 2.63\n",
      "Iteration 300/500, Latency: 0.3798s, FPS: 2.63\n",
      "Iteration 310/500, Latency: 0.3747s, FPS: 2.67\n",
      "Iteration 320/500, Latency: 0.3794s, FPS: 2.64\n",
      "Iteration 330/500, Latency: 0.3790s, FPS: 2.64\n",
      "Iteration 340/500, Latency: 0.3776s, FPS: 2.65\n",
      "Iteration 350/500, Latency: 0.3790s, FPS: 2.64\n",
      "Iteration 360/500, Latency: 0.3819s, FPS: 2.62\n",
      "Iteration 370/500, Latency: 0.3775s, FPS: 2.65\n",
      "Iteration 380/500, Latency: 0.3758s, FPS: 2.66\n",
      "Iteration 390/500, Latency: 0.3776s, FPS: 2.65\n",
      "Iteration 400/500, Latency: 0.3857s, FPS: 2.59\n",
      "Iteration 410/500, Latency: 0.3819s, FPS: 2.62\n",
      "Iteration 420/500, Latency: 0.3865s, FPS: 2.59\n",
      "Iteration 430/500, Latency: 0.3839s, FPS: 2.60\n",
      "Iteration 440/500, Latency: 0.3920s, FPS: 2.55\n",
      "Iteration 450/500, Latency: 0.3904s, FPS: 2.56\n",
      "Iteration 460/500, Latency: 0.3847s, FPS: 2.60\n",
      "Iteration 470/500, Latency: 0.3765s, FPS: 2.66\n",
      "Iteration 480/500, Latency: 0.3789s, FPS: 2.64\n",
      "Iteration 490/500, Latency: 0.3803s, FPS: 2.63\n",
      "\n",
      "Evaluation complete on BiseNet with 20 epochs, 2 batch size, and balanced=False.\n",
      "\n",
      "Pixel Accuracy: 36.97%\n",
      "Per-class IoU: [1.71027151e-02 3.36944317e-02 4.94138285e-01 1.71455344e-02\n",
      " 9.93007586e-02 7.23707055e-02 8.10750470e-02 7.40046515e-02\n",
      " 5.69226351e-01 4.26893824e-02 4.13820523e-01 3.31013026e-01\n",
      " 6.34908458e-03 2.89271584e-01 7.87583436e-03 9.51967331e-03\n",
      " 0.00000000e+00 1.11529619e-03 2.29005942e-04]\n",
      "Mean IoU: 0.13473378362898827\n",
      "Mean Latency: 390.05 ms\n",
      "Latency Std Dev: 23.74 ms\n",
      "Mean FPS: 2.57\n",
      "FPS Std Dev: 0.13\n",
      "| module                                      | #parameters or shape   | #flops     |\n",
      "|:--------------------------------------------|:-----------------------|:-----------|\n",
      "| model                                       | 12.582M                | 25.78G     |\n",
      "|  saptial_path                               |  0.371M                |  5.088G    |\n",
      "|   saptial_path.convblock1                   |   1.856K               |   0.243G   |\n",
      "|    saptial_path.convblock1.conv1            |    1.728K              |    0.226G  |\n",
      "|    saptial_path.convblock1.bn               |    0.128K              |    16.777M |\n",
      "|   saptial_path.convblock2                   |   73.984K              |   2.424G   |\n",
      "|    saptial_path.convblock2.conv1            |    73.728K             |    2.416G  |\n",
      "|    saptial_path.convblock2.bn               |    0.256K              |    8.389M  |\n",
      "|   saptial_path.convblock3                   |   0.295M               |   2.42G    |\n",
      "|    saptial_path.convblock3.conv1            |    0.295M              |    2.416G  |\n",
      "|    saptial_path.convblock3.bn               |    0.512K              |    4.194M  |\n",
      "|  context_path.features                      |  11.69M                |  19.002G   |\n",
      "|   context_path.features.conv1               |   9.408K               |   1.233G   |\n",
      "|    context_path.features.conv1.weight       |    (64, 3, 7, 7)       |            |\n",
      "|   context_path.features.bn1                 |   0.128K               |   16.777M  |\n",
      "|    context_path.features.bn1.weight         |    (64,)               |            |\n",
      "|    context_path.features.bn1.bias           |    (64,)               |            |\n",
      "|   context_path.features.layer1              |   0.148M               |   4.849G   |\n",
      "|    context_path.features.layer1.0           |    73.984K             |    2.424G  |\n",
      "|    context_path.features.layer1.1           |    73.984K             |    2.424G  |\n",
      "|   context_path.features.layer2              |   0.526M               |   4.305G   |\n",
      "|    context_path.features.layer2.0           |    0.23M               |    1.885G  |\n",
      "|    context_path.features.layer2.1           |    0.295M              |    2.42G   |\n",
      "|   context_path.features.layer3              |   2.1M                 |   4.3G     |\n",
      "|    context_path.features.layer3.0           |    0.919M              |    1.882G  |\n",
      "|    context_path.features.layer3.1           |    1.181M              |    2.418G  |\n",
      "|   context_path.features.layer4              |   8.394M               |   4.298G   |\n",
      "|    context_path.features.layer4.0           |    3.673M              |    1.881G  |\n",
      "|    context_path.features.layer4.1           |    4.721M              |    2.417G  |\n",
      "|   context_path.features.fc                  |   0.513M               |            |\n",
      "|    context_path.features.fc.weight          |    (1000, 512)         |            |\n",
      "|    context_path.features.fc.bias            |    (1000,)             |            |\n",
      "|  attention_refinement_module1               |  66.304K               |  0.59M     |\n",
      "|   attention_refinement_module1.conv         |   65.792K              |   65.536K  |\n",
      "|    attention_refinement_module1.conv.weight |    (256, 256, 1, 1)    |            |\n",
      "|    attention_refinement_module1.conv.bias   |    (256,)              |            |\n",
      "|   attention_refinement_module1.bn           |   0.512K               |   0.512K   |\n",
      "|    attention_refinement_module1.bn.weight   |    (256,)              |            |\n",
      "|    attention_refinement_module1.bn.bias     |    (256,)              |            |\n",
      "|   attention_refinement_module1.avgpool      |                        |   0.524M   |\n",
      "|  attention_refinement_module2               |  0.264M                |  0.525M    |\n",
      "|   attention_refinement_module2.conv         |   0.263M               |   0.262M   |\n",
      "|    attention_refinement_module2.conv.weight |    (512, 512, 1, 1)    |            |\n",
      "|    attention_refinement_module2.conv.bias   |    (512,)              |            |\n",
      "|   attention_refinement_module2.bn           |   1.024K               |   1.024K   |\n",
      "|    attention_refinement_module2.bn.weight   |    (512,)              |            |\n",
      "|    attention_refinement_module2.bn.bias     |    (512,)              |            |\n",
      "|   attention_refinement_module2.avgpool      |                        |   0.262M   |\n",
      "|  supervision1                               |  4.883K                |            |\n",
      "|   supervision1.weight                       |   (19, 256, 1, 1)      |            |\n",
      "|   supervision1.bias                         |   (19,)                |            |\n",
      "|  supervision2                               |  9.747K                |            |\n",
      "|   supervision2.weight                       |   (19, 512, 1, 1)      |            |\n",
      "|   supervision2.bias                         |   (19,)                |            |\n",
      "|  feature_fusion_module                      |  0.176M                |  1.435G    |\n",
      "|   feature_fusion_module.convblock           |   0.175M               |   1.435G   |\n",
      "|    feature_fusion_module.convblock.conv1    |    0.175M              |    1.434G  |\n",
      "|    feature_fusion_module.convblock.bn       |    38                  |    0.311M  |\n",
      "|   feature_fusion_module.conv1               |   0.38K                |   0.361K   |\n",
      "|    feature_fusion_module.conv1.weight       |    (19, 19, 1, 1)      |            |\n",
      "|    feature_fusion_module.conv1.bias         |    (19,)               |            |\n",
      "|   feature_fusion_module.conv2               |   0.38K                |   0.361K   |\n",
      "|    feature_fusion_module.conv2.weight       |    (19, 19, 1, 1)      |            |\n",
      "|    feature_fusion_module.conv2.bias         |    (19,)               |            |\n",
      "|   feature_fusion_module.avgpool             |                        |   0.156M   |\n",
      "|  conv                                       |  0.38K                 |  0.189G    |\n",
      "|   conv.weight                               |   (19, 19, 1, 1)       |            |\n",
      "|   conv.bias                                 |   (19,)                |            |\n",
      "Total FLOPs: 25.78 GFLOPs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'label_dir_emanuele = \"C:/Users/marti/OneDrive/Desktop/HW_Masone/MLDL2024_project1/datasets/Cityscapes/Cityscapes/Cityscapes/gtFine/train\"\\nclass_frequencies = compute_class_weights(dataset_path_emanuele + \"/gtFine/train\", num_classes=19)\\nfor class_idx, freq in class_frequencies.items():\\n    print(f\"Metric {class_idx}:\")\\n    for i in range(len(freq)):\\n        print(f\"Class {i}: {freq[i]}; \")\\n    print(\"\\n\")'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from train import deeplab_train, deeplab_test, bisenet_test, bisenet_on_gta\n",
    "from utils import compute_class_weights, convert_weights_format\n",
    "import os\n",
    "import torch\n",
    "\n",
    "dataset_path_alberto = \"/home/alberto/Documenti/Materiale scuola Alberto/MLDL2024_project1/datasets/Cityscapes/Cityspaces\"\n",
    "#dataset_path_emanuele = \"C:/Users/marti/OneDrive/Desktop/HW_Masone/MLDL2024_project1/datasets/Cityscapes/Cityscapes/Cityscapes\"\n",
    "workspace_path = \"/home/alberto/Documenti/Materiale scuola Alberto/MLDL2024_project1\"\n",
    "pretrained_image_path = \"/home/alberto/Documenti/Materiale scuola Alberto/MLDL2024_project1/deeplab_resnet_pretrained_imagenet.pth\"\n",
    "num_epochs = 1\n",
    "#deeplab_train(dataset_path_alberto, workspace_path, pretrained_image_path, num_epochs)\n",
    "\n",
    "model_path = workspace_path + \"/export/bisenet_gta_epoch_20_0001.pth\"\n",
    "\n",
    "#deeplab_test(dataset_path_emanuele, model_path)\n",
    "#convert_weights_format(model_path, 50, 2, False, context_path='resnet18')\n",
    "bisenet_test(dataset_path_alberto, model_path)\n",
    "\n",
    "gta_path = \"/home/alberto/Documenti/Materiale scuola Alberto/MLDL2024_project1/datasets/GTA5\"\n",
    "gta_model = \"/home/alberto/Documenti/Materiale scuola Alberto/MLDL2024_project1/export/bisenet_on_gta_final_4_batches_balanced_polylr.pth\"\n",
    "#bisenet_on_gta(gta_path, workspace_path, num_epochs)\n",
    "#bisenet_test(dataset_path_alberto, gta_model)\n",
    "\n",
    "\n",
    "\n",
    "# Compute class weights\n",
    "\"\"\"label_dir_emanuele = \"C:/Users/marti/OneDrive/Desktop/HW_Masone/MLDL2024_project1/datasets/Cityscapes/Cityscapes/Cityscapes/gtFine/train\"\n",
    "class_frequencies = compute_class_weights(dataset_path_emanuele + \"/gtFine/train\", num_classes=19)\n",
    "for class_idx, freq in class_frequencies.items():\n",
    "    print(f\"Metric {class_idx}:\")\n",
    "    for i in range(len(freq)):\n",
    "        print(f\"Class {i}: {freq[i]}; \")\n",
    "    print(\"\\n\")\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
